<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Single tree model | Mixed BART Models: maths and discussion</title>
  <meta name="description" content="Chapter 2 Single tree model | Mixed BART Models: maths and discussion" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Single tree model | Mixed BART Models: maths and discussion" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Single tree model | Mixed BART Models: maths and discussion" />
  
  
  

<meta name="author" content="Bruna Wundervald" />


<meta name="date" content="2021-10-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="finding-a-new-conditional-for-mu-j.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Mixed BART book</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Intro</a></li>
<li class="chapter" data-level="2" data-path="single-tree-model.html"><a href="single-tree-model.html"><i class="fa fa-check"></i><b>2</b> Single tree model</a>
<ul>
<li class="chapter" data-level="2.1" data-path="single-tree-model.html"><a href="single-tree-model.html#model-specification"><i class="fa fa-check"></i><b>2.1</b> Model specification</a></li>
<li class="chapter" data-level="2.2" data-path="single-tree-model.html"><a href="single-tree-model.html#maths"><i class="fa fa-check"></i><b>2.2</b> Maths</a></li>
<li class="chapter" data-level="2.3" data-path="single-tree-model.html"><a href="single-tree-model.html#posteriors"><i class="fa fa-check"></i><b>2.3</b> Posteriors</a></li>
<li class="chapter" data-level="2.4" data-path="single-tree-model.html"><a href="single-tree-model.html#posterior-for-tau"><i class="fa fa-check"></i><b>2.4</b> Posterior for <span class="math inline">\(\tau\)</span></a></li>
<li class="chapter" data-level="2.5" data-path="single-tree-model.html"><a href="single-tree-model.html#posterior-for-mu_j"><i class="fa fa-check"></i><b>2.5</b> Posterior for <span class="math inline">\(\mu_j\)</span></a></li>
<li class="chapter" data-level="2.6" data-path="single-tree-model.html"><a href="single-tree-model.html#posterior-for-mu"><i class="fa fa-check"></i><b>2.6</b> Posterior for <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="2.7" data-path="single-tree-model.html"><a href="single-tree-model.html#a-second-posterior-with-mu_j-marginalised-out"><i class="fa fa-check"></i><b>2.7</b> A second posterior, with <span class="math inline">\(\mu_j\)</span> marginalised out</a></li>
<li class="chapter" data-level="2.8" data-path="single-tree-model.html"><a href="single-tree-model.html#marginal-distributions-for-y"><i class="fa fa-check"></i><b>2.8</b> Marginal Distributions for y</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="single-tree-model.html"><a href="single-tree-model.html#log-version-of-the-marginal"><i class="fa fa-check"></i><b>2.8.1</b> log version of the marginal:</a></li>
<li class="chapter" data-level="2.8.2" data-path="single-tree-model.html"><a href="single-tree-model.html#old-marginal-distributions"><i class="fa fa-check"></i><b>2.8.2</b> (Old) Marginal Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="single-tree-model.html"><a href="single-tree-model.html#algorithm"><i class="fa fa-check"></i><b>2.9</b> Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="finding-a-new-conditional-for-mu-j.html"><a href="finding-a-new-conditional-for-mu-j.html"><i class="fa fa-check"></i><b>3</b> Finding a new conditional for <span class="math inline">\(\mu_j\)</span></a>
<ul>
<li class="chapter" data-level="3.1" data-path="finding-a-new-conditional-for-mu-j.html"><a href="finding-a-new-conditional-for-mu-j.html#example-code"><i class="fa fa-check"></i><b>3.1</b> Example code</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="parameter-change.html"><a href="parameter-change.html"><i class="fa fa-check"></i><b>4</b> Parameter change</a></li>
<li class="chapter" data-level="5" data-path="a-bart-version-of-our-hierachical-trees-model.html"><a href="a-bart-version-of-our-hierachical-trees-model.html"><i class="fa fa-check"></i><b>5</b> A BART version of our hierachical trees model</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="6" data-path="checking-posteriors-by-simulation.html"><a href="checking-posteriors-by-simulation.html"><i class="fa fa-check"></i><b>6</b> Checking posteriors by simulation</a>
<ul>
<li class="chapter" data-level="6.1" data-path="checking-posteriors-by-simulation.html"><a href="checking-posteriors-by-simulation.html#high-k-2.5"><i class="fa fa-check"></i><b>6.1</b> ‘High’ k: 2.5</a></li>
<li class="chapter" data-level="6.2" data-path="checking-posteriors-by-simulation.html"><a href="checking-posteriors-by-simulation.html#small-k-0.5"><i class="fa fa-check"></i><b>6.2</b> ‘Small’ k: 0.5</a></li>
<li class="chapter" data-level="6.3" data-path="checking-posteriors-by-simulation.html"><a href="checking-posteriors-by-simulation.html#y-k_1-tau_mu-mu_mu-alpha-beta-evaluating-parameter-grids-for-k_1-mu_mu-beta-and-alpha"><i class="fa fa-check"></i><b>6.3</b> <span class="math inline">\(y | k_1, \tau_{\mu}, \mu_{\mu}, \alpha, \beta\)</span>: Evaluating parameter grids for <span class="math inline">\(k_1\)</span>, <span class="math inline">\(\mu_{\mu}\)</span>, <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\alpha\)</span></a></li>
<li class="chapter" data-level="6.4" data-path="checking-posteriors-by-simulation.html"><a href="checking-posteriors-by-simulation.html#code"><i class="fa fa-check"></i><b>6.4</b> Code</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/brunaw/mixed_bart" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mixed BART Models: maths and discussion</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="single-tree-model" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Single tree model</h1>
<div id="model-specification" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Model specification</h2>
<p>Define the following model. Suppose we have the observation of a tree node as:
<span class="math display">\[y_{ij}, i = 1,\ldots,n_j, \; j = 1\ldots, m\]</span>
where <span class="math inline">\(y_{ij}\)</span> is observation <span class="math inline">\(i\)</span> in group <span class="math inline">\(j\)</span>. There are different numbers of observations <span class="math inline">\(n_j\)</span> in each group, so for example <span class="math inline">\(n_1\)</span> is the number of observations in group 1, etc. There are <span class="math inline">\(m\)</span> groups. The total number of observations is <span class="math inline">\(n = \sum_{j=1}^m n_j\)</span></p>
<p>Then, for each tree node, suppose we have the likelihood:
<span class="math display">\[y_{ij} \sim N(\mu_j, \tau^{-1})\]</span></p>
<p>so each group has an overall mean <span class="math inline">\(\mu_j\)</span>, with an overall precision term <span class="math inline">\(\tau\)</span>.</p>
<p>We then have a hierarchical prior distribution:</p>
<p><span class="math display">\[\mu_j \sim N(\mu, k_1 (\tau^{-1}))\]</span></p>
<p>where <span class="math inline">\(k_1\)</span> will be taken as a constant for simplicity,
and the hyper-parameter prior distributions are:</p>
<p><span class="math display">\[\mu \sim N(0, \tau_{\mu} = k_2 (\tau^{-1}))\]</span>
<span class="math display">\[\tau \sim Ga(\alpha, \beta)\]</span></p>
<p>Where the values <span class="math inline">\(k_1, k_2, \alpha, \beta\)</span> are all fixed.</p>
</div>
<div id="maths" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Maths</h2>
<ul>
<li>The likelihood of each tree node will be:</li>
</ul>
<p><span class="math display">\[\begin{equation}
L = \prod_{j = 1}^{m} \prod_{i = 1}^{n_j} p(y_{ij} | \mu_{j}, \tau) \\
L \propto \tau^{n/2} exp \{ -\frac{\tau}{2} \sum_{j = 1}^{m}
\sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2 \}
\end{equation}\]</span></p>
<p>with prior distributions:</p>
<ul>
<li><span class="math inline">\(\mu_j | \mu, \tau, k_1\)</span></li>
</ul>
<p><span class="math display">\[\begin{equation}
p(\mu_1, \dots, \mu_m | \mu, \tau) \propto (\tau/k_1)^{m/2}
exp\{ - \frac{\tau}{2k_1} \sum_{j = 1}^{m} (\mu_j - \mu)^2  \}
\end{equation}\]</span></p>
<ul>
<li><span class="math inline">\(\tau | \alpha, \beta\)</span></li>
</ul>
<p><span class="math display">\[p(\tau | \alpha, \beta) \propto \tau^{\alpha - 1} exp\{ - \beta \tau \}\]</span></p>
<ul>
<li><span class="math inline">\(\mu | \tau_{\mu} = k_2 (\tau^{-1})\)</span></li>
</ul>
<p><span class="math display">\[\begin{equation}
p(\mu | k_2, \tau) \propto (\tau/k_2)^{1/2}
exp\{ - \frac{ \tau}{2 k_2} \mu^2  \}  \}
\end{equation}\]</span></p>
<p>and their joint distribution as:</p>
<ul>
<li><span class="math inline">\(p(\tau, \mu_1, \dots, \mu_m, \mu| y, k_1, k_2, \tau, \alpha, \beta)\)</span></li>
</ul>
<p><span class="math display">\[\begin{equation}
p(\tau, \mu_1, \dots, \mu_m, \mu| y, k_1, k_2, \tau, \alpha, \beta)
\propto

\tau^{\alpha - 1} exp\{ - \beta \tau \} \times \\

(\tau/k_1)^{m/2}
exp\{ - \frac{\tau}{2k_1} \sum_{j = 1}^{m} (\mu_j - \mu)^2  \} \\ 
\times  
(\tau/k_2)^{1/2}
exp\{ - \frac{ \tau}{2 k_2} \mu^2  \} 
\times \tau^{n/2} exp \{ -\frac{\tau}{2} \sum_{j = 1}^{m}
\sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2 \}
\end{equation}\]</span></p>

</div>
<div id="posteriors" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Posteriors</h2>
</div>
<div id="posterior-for-tau" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Posterior for <span class="math inline">\(\tau\)</span></h2>
<ul>
<li><span class="math inline">\(p(\tau | \mu_1, \dots, \mu_m, y, \alpha, \beta, k_1)\)</span></li>
</ul>
<p><span class="math display">\[\begin{equation}
p(\tau | \mu_1, \dots, \mu_m, y, \alpha, \beta, k_1) \propto
\tau^{\alpha - 1} exp\{ - \beta \tau \}  \times \\

(\tau/k_1)^{m/2} exp \{ -\frac{\tau}{2k_1} \sum_{j = 1}^{m}
(\mu_{j} - \mu)^2 \} \times \\

\tau^{n/2} exp \{ -\frac{\tau}{2} \sum_{j = 1}^{m}
\sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2 \} \times
(\tau/k_2)^{1/2}
exp\{ - \frac{ \tau}{2 k_2} \mu^2  \}  \\

\propto \tau^{(n+m+1)/2  + \alpha - 1 }
exp \{ - \tau \Big( \frac{\sum_{j = 1}^{m}
\sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2}{2} + \beta  +
\frac{\sum_{j = 1}^{m}(\mu_{j} - \mu)^2}{2k_1} +
\frac{\mu^2}{2k_2}\Big) \}
\end{equation}\]</span></p>
<p>So <span class="math inline">\(\tau | \mu_1, \dots, \mu_m, y, \alpha, \beta, k_1, k_2 \sim \\ \text{Gamma}((n+m+1)/2 + \alpha, \Big( \frac{\sum_{j = 1}^{m} \sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2}{2} + \beta + \frac{\sum_{j = 1}^{m}(\mu_{j} - \mu)^2}{2k_1} + \frac{\mu^2}{2k_2})\Big)\)</span></p>
</div>
<div id="posterior-for-mu_j" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Posterior for <span class="math inline">\(\mu_j\)</span></h2>
<p><span class="math display">\[\begin{equation}
Q =    (\tau/k_1) \sum_{j=1}^{m} (\mu_j - \mu)^2 + 
\tau \sum_{j = 1}^{m} \sum_{i = 1}^{n_j} (y_{ij} - \mu_j)^2 \\

Q =    \tau [ \sum_{j = 1}^{m} n_j \mu_j^2 + \frac{\mu_j^2}{k_1} -  
(\sum_{j = 1}^{m} \frac{2 \mu \mu_j}{k_1} + 2 \bar y_j n_j \mu_j)] \\

Q \propto    \tau [ \sum_{j = 1}^{m} (n_j + \frac{1}{k_1}) \mu_j^2 -  
2 \mu_j (\frac{\mu}{k_1} +  \bar y_j n_j )] \\

Q \propto [ \sum_{j = 1}^{m} (n_j + \frac{1}{k_1})(\mu_j -  
 \frac{\mu/k_1 +  \bar y_j n_j}{n_j + 1/k_1})^2]\\

\end{equation}\]</span>
So for each <span class="math inline">\(\mu_j\)</span></p>
<p><span class="math display">\[\mu_j | \mu, y, \tau, k_1 \sim N(\frac{\mu/k_1 +  \bar y_j n_j}{n_j + 1/k_1}, ((n_j + \frac{1}{k_1}) \tau )^{-1})\]</span></p>
</div>
<div id="posterior-for-mu" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> Posterior for <span class="math inline">\(\mu\)</span></h2>
<p>Similarly, for <span class="math inline">\(\mu\)</span> we have:</p>
<p><span class="math display">\[\begin{equation}
Q =    \frac{\tau}{k_1} \sum_{j = 1}^{m} (\mu_j - \mu)^2 +  \frac{ \tau}{k_2} \mu^2 \\

Q =    \frac{\tau}{k_1}  \sum_{j=1}^{m} (\mu_j^{2} - 2 \mu \mu_j + \mu^2) + 
  \frac{ \tau}{k_2} \mu^2 \\


Q \propto (\frac{\tau}{k_2} + \frac{\tau}{k_1}  m ) \mu^2 - 
\frac{2\tau}{k_1} \sum_{j=1}^{m} \mu \mu_j \\

Q \propto (\frac{\tau}{k_2} + \frac{\tau}{k_1}  m ) \mu^2 - 
\frac{2\tau}{k_1}  \mu \bar \mu m \\


Q \propto (\tau(\frac{m}{k_1} + \frac{1}{k_2}))(\mu - 
\frac{(\tau/k_1) \bar \mu m}{\tau(\frac{m}{k_1} + \frac{1}{k_2})})^2 
\end{equation}\]</span></p>
<p>So for <span class="math inline">\(\mu\)</span> we have that the conditional distribution:</p>
<p><span class="math display">\[\mu | \mu_1, \dots, \mu_{m}, \mu_{\mu}, k_1, k_2, \tau \sim N(
\frac{(\tau/k_1) \bar \mu m}{\tau(\frac{m}{k_1} + \frac{1}{k_2})},
(\tau(\frac{m}{k_1} + \frac{1}{k_2}))^{-1})\]</span></p>
</div>
<div id="a-second-posterior-with-mu_j-marginalised-out" class="section level2" number="2.7">
<h2><span class="header-section-number">2.7</span> A second posterior, with <span class="math inline">\(\mu_j\)</span> marginalised out</h2>
<p>Assuming
<span class="math display">\[ y | \tau, k_1, k_2 \sim N(0, \tau^{-1}[(k_1 \mathbf{M}\mathbf{M}^{T} + \mathbf{I}) + k_2 \mathbf{1}\mathbf{1}^{T}])\]</span></p>
<p>we can do</p>
<p><span class="math display">\[\begin{equation}
p(\mu | y, \alpha, \beta, k_1, k_2) \propto
\exp \{ -\frac{\tau}{2}(\mathbf{y} - \mu \mathbf{1})^{T} \Psi^{-1}
(\mathbf{y} - \mu \mathbf{1}) \} \times \\
\exp \{ -\frac{\tau}{2 k_2} \mu^{2} \} \\ 

 \propto
\exp \{ -\frac{\tau}{2}(\mu^{2} (\mathbf{1}^{T} \Psi^{-1} \mathbf{1}
+ 1/k_2) - 2 \mu \mathbf{1}^{T} \Psi^{-1} \mathbf{y} + \mu^2/k_2) \}
\\

\propto
\exp \{ -\frac{\tau}{2}[(
\mathbf{1}^{T} \Psi^{-1} \mathbf{1}+ 1/k_2)(
\mu^2  - 
\frac{2 \mu \mathbf{1}^{T} \Psi^{-1} \mathbf{y}}{\mathbf{1}^{T} \Psi^{-1} \mathbf{1} + 1/k_1}) \}
\\
\end{equation}\]</span></p>
<p><span class="math display">\[\mu | y, \tau, k_1, k_2 \sim MVN(\frac{\mathbf{1}^{T}\Psi^{-1}\mathbf{y}}{\mathbf{1}^{T}\Psi^{-1}\mathbf{1} + k_2^{-1}}, 
((\mathbf{1}^{T}\Psi^{-1}\mathbf{1} + k_2^{-1}) \tau )^{-1})\]</span></p>

</div>
<div id="marginal-distributions-for-y" class="section level2" number="2.8">
<h2><span class="header-section-number">2.8</span> Marginal Distributions for y</h2>
<p>Suppose we have the outcome variable:
<span class="math display">\[\mathbf{y} \sim MVN_n(\mu \mathbf{1}_n, \tau^{-1} (k_1 \mathbf{MM}^T + \mathbf{I}))\]</span></p>
<p>with:
<span class="math display">\[\mu \sim N(\mu_\mu, \tau_\mu^{-1})\]</span></p>
<p>And define <span class="math inline">\(\mathbf{\Psi} = k_1 \mathbf{MM}^T + \mathbf{I}\)</span></p>
<p>Then, as a ‘trick’ to estimate the mean and variance of <span class="math inline">\(\mathbf{y}\)</span>, we can write:</p>
<p><span class="math display">\[\mathbf{y} = \mu \mathbf{1}_n + \left[ \tau^{-1} \Psi \right]^{1/2} \mathbf{z}\]</span></p>
<p>where <span class="math inline">\(\mathbf{z} \sim MVN(0, \mathbf{I})\)</span> is a standard multivariate normal. Then we have:</p>
<p><span class="math display">\[E(\mathbf{y}) = \mu_\mu \mathbf{1}_n + 0 = \mu_\mu \mathbf{1}_n \\ 
Var(\mathbf{y}) = Var(\mu \mathbf{1}_n) + 
Var(\left[\tau^{-1} \Psi \right]^{1/2}) = \tau_{\mu}^{-1} \mathbf{1}_n \mathbf{1}^T_n + \tau^{-1} \mathbf{\Psi}\]</span></p>
<p>Now let <span class="math inline">\(\tau_\mu^{-1} = k_2 \tau^{-1}\)</span>, we get:</p>
<p><span class="math display">\[\mathbf{y} \sim MVN(\mu_\mu \mathbf{1}, \tau^{-1} \left[ k_2 \mathbf{1}_n \mathbf{1}^T_n  +  \mathbf{\Psi} \right]) \equiv MVN(W_0, \tau^{-1} W_1)\]</span></p>
<p>We now want to marginalize this over <span class="math inline">\(\tau \sim Ga(\alpha, \beta)\)</span>, by integrating out a Gamma distribution with:</p>
<p><span class="math display">\[ Ga\Big(n/2 + \alpha, \beta + \frac{(\mathbf{y} - \mathbf{W}_0)^T \mathbf{W}_1^{-1} (\mathbf{y} - \mathbf{W}_0)}{2}\Big) \]</span></p>
<p>…so we get:</p>
<p><span class="math display">\[\pi(\mathbf{y} | \mu_\mu, k_1, k_2) = \int 
(2\pi)^{-n/2}
\tau^{n/2} | \mathbf{W}_1 |^{-1/2} \exp \left[ -\frac{\tau}{2} (\mathbf{y} - \mathbf{W}_0)^T \mathbf{W}_1^{-1} (\mathbf{y} - \mathbf{W}_0)\right] \tau^{\alpha - 1} \exp(-\beta \tau) \partial \tau\]</span></p>
<p>This becomes:</p>
<p><span class="math display">\[ = (2\pi)^{-n/2} | \mathbf{W}_1 |^{-1/2} \Gamma \left( \frac{n}{2} + \alpha \right) \left[ \frac{(\mathbf{y} - \mathbf{W}_0)^T \mathbf{W}_1^{-1} (\mathbf{y} - \mathbf{W}_0)}{2} + \beta\right]^{-\left(\frac{n}{2} + \alpha \right)}\]</span></p>
<p>(For examples of the evaluation of this marginal
distribution, see )</p>
<div id="log-version-of-the-marginal" class="section level3" number="2.8.1">
<h3><span class="header-section-number">2.8.1</span> log version of the marginal:</h3>
<p>This equation in log-scale gives us:</p>
<p><span class="math display">\[\begin{eqnarray*}
\log(\pi(\boldsymbol{y} | k_1, k_2, \mu, \alpha, \beta)) &amp;=&amp; 
-\frac{N}{2} \log(2\pi) 
-\frac{1}{2} \log(|\boldsymbol{\mathbf{W}}_{1}|) + 
\log(\Gamma(N/2 + \alpha)) \\
&amp;-&amp; (N/2 + \alpha)\left[ \log \Big( \beta + 
\frac{(\mathbf{y} - \mathbf{W}_{0})^T \mathbf{W}_{1}^{-1} (\mathbf{y} - \mathbf{W}_{0})}{2}\Big) \right]
\end{eqnarray*}\]</span></p>
<p>And the same, when written for <span class="math inline">\(j = 1,\dots, b\)</span> nodes
of a tree, would look like:</p>
<p><span class="math display">\[\begin{eqnarray*}
\sum_{j = 1}^{b} \log(\pi(\boldsymbol{y_{j}} | N_j, k_1, k_2, \mu, \alpha, \beta)) &amp;=&amp; \sum_{j = 1}^{b}
-\frac{N_j}{2} \log(2\pi) +
-\frac{1}{2} \log(|\boldsymbol{\mathbf{W}}_{1,j}|) + 
\log(\Gamma(N_j/2 + \alpha)) \\
&amp;-&amp; (N_j/2 + \alpha)\left[ \log \Big(\beta + 
\frac{(\mathbf{y}_j - \mathbf{W}_{0,j})^T \mathbf{W}_{1,j}^{-1} (\mathbf{y}_j - \mathbf{W}_{0,j})}{2} \Big) \right]
\end{eqnarray*}\]</span></p>
</div>
<div id="old-marginal-distributions" class="section level3" number="2.8.2">
<h3><span class="header-section-number">2.8.2</span> (Old) Marginal Distributions</h3>
<p>This is only present here for the record.</p>
<p><span class="math display">\[y_{ij} \sim N(\mu_j, \tau^{-1})\]</span>
<span class="math display">\[\mu_j \sim N(\mu, k\tau^{-1})\]</span>
<span class="math display">\[\mu \sim N(\mu_\mu,\tau_\mu^{-1})\]</span>
<span class="math display">\[\tau \sim Ga(\alpha, \beta)\]</span></p>
<p>with <span class="math inline">\(N = \sum_{j = 1}^{m} n_j\)</span>. Define <span class="math inline">\(\mathbf{M}\)</span> to be an <span class="math inline">\(N\times m\)</span> binary matrix which allocates each observation to a group.</p>
<p>Writing things out in matrix format:</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{y} = 
\begin{bmatrix}
    y_{11}       \\
    y_{21}       \\
    \vdots        \\
    y_{n_m m}      
\end{bmatrix}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{M} = 
\begin{bmatrix}
    0    &amp; 1   &amp; 0 \\
    1    &amp; 0   &amp; 0 \\
    1    &amp; 0   &amp; 0 \\
    \vdots &amp; \vdots &amp; \vdots        \\
    0    &amp; 0    &amp; 1 
\end{bmatrix}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{\lambda} = 
\begin{bmatrix}
    \lambda_1       \\
    \vdots        \\
    \lambda_m
\end{bmatrix}
\end{equation}\]</span></p>
<p>then <span class="math inline">\(\boldsymbol{y} \sim MVN_{N}( \boldsymbol{M \lambda}, \tau^{-1} \boldsymbol{I})\)</span> and <span class="math inline">\(\boldsymbol{\lambda} \sim MVN_{m}( \mu \boldsymbol{1}, k \tau^{-1} \boldsymbol{I})\)</span>.</p>
<p><span class="math display">\[\begin{equation}
E[\boldsymbol{y} | \mu, \tau] = E_\lambda E_y[\boldsymbol{y} | \boldsymbol{\lambda}, \mu, \tau] =
\boldsymbol{M} E[\boldsymbol{\lambda}] = \mu \boldsymbol{M1} \\

Var[\boldsymbol{y} | \mu, \tau] = Var[\boldsymbol{M} \boldsymbol{\lambda}] +
\tau^{-1} \boldsymbol{I} = \boldsymbol{M} \boldsymbol{M}^{T}(k\tau^{-1}) + \tau^{-1} \boldsymbol{I}

\end{equation}\]</span></p>
<p>so
<span class="math display">\[\boldsymbol{y} | \mu, \tau, k, \tau_{\mu} \sim MVN_{N}(\mu \boldsymbol{M1} , \boldsymbol{M} \boldsymbol{M}^{T}(k\tau^{-1}) + \tau^{-1} \boldsymbol{I})\]</span></p>
<p><span class="math display">\[\boldsymbol{y} | \mu, \tau, k, \tau_{\mu} \sim MVN_{N}(\mu \boldsymbol{M1} , k\tau^{-1} + \tau^{-1} \boldsymbol{I}), \text{ since } \boldsymbol{M} \boldsymbol{M}^{T} = \boldsymbol{I}\]</span></p>
<p><span class="math display">\[\boldsymbol{y} | \mu, \tau, k, \tau_{\mu} \sim MVN_{N}(\mu \boldsymbol{M1} , \tau^{-1} (k + \boldsymbol{I}) )\]</span></p>
<p>We now use this as the starting point and integrate out <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span>. The equation we end up with should be a function of <span class="math inline">\(M\)</span>, <span class="math inline">\(k\)</span>, <span class="math inline">\(\tau_\mu\)</span>, <span class="math inline">\(\alpha\)</span>, and <span class="math inline">\(\beta\)</span>.</p>
<p>To start, define: <span class="math inline">\(\Psi = (k + \boldsymbol{I})\)</span> so that <span class="math inline">\(y|\ldots \sim MVN(\mu \boldsymbol{M1}, \tau^{-1} \boldsymbol{\Psi})\)</span>. Then we obtain:</p>
<p><span class="math display">\[\begin{eqnarray*}
\pi(\boldsymbol{y} | k, \tau_\mu, \mu_\mu, \alpha, \beta) &amp;=&amp; \int \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times \tau_\mu^{1/2} \exp \left[ -\frac{\tau_\mu}{2} (\mu - \mu_\mu)^2 \right]\\
&amp;\times&amp;  \tau^{N/2} |\Psi|^{-1/2}  \exp \left[ -\frac{\tau}{2} \left\{  (\boldsymbol{y} - \mu \boldsymbol{M1})^T \boldsymbol{\Psi}^{-1} (\boldsymbol{y} - \mu \boldsymbol{M1}) \right\} \right] \partial\mu \partial\tau \\ 

&amp;=&amp; \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times \tau_\mu^{1/2} 
 \tau^{N/2} |\Psi|^{-1/2}\partial\tau  \\
&amp;\times&amp; \int \exp \left[ -\frac{1}{2} [\tau_\mu (\mu - \mu_\mu)^2 + \tau (\boldsymbol{y} - \mu \boldsymbol{M1})^T \boldsymbol{\Psi}^{-1}  (\boldsymbol{y} - \mu \boldsymbol{M1})] \right]  \partial\mu \\ 


\end{eqnarray*}\]</span></p>
<p>The inner expression can be rewritten as:</p>
<p><span class="math display">\[\begin{eqnarray*}
Q &amp;=&amp;
[\tau_\mu (\mu - \mu_\mu)^2 + \tau (\boldsymbol{y} - \mu \boldsymbol{M1})^T \boldsymbol{\Psi}^{-1}  (\boldsymbol{y} - \mu \boldsymbol{M1})] \\

&amp;=&amp; \mu^2(\tau_{\mu} + \tau (\boldsymbol{M1})^{T}\boldsymbol{\Psi}^{-1}     \boldsymbol{M1}) - 2\mu (\tau_{\mu} \mu_{\mu} + 
\tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}) + \tau_{\mu} \mu_{\mu}^2 +
\tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}  \boldsymbol{y} \\

&amp;=&amp; \mu^2(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1}) - 2\mu (\tau_{\mu} \mu_{\mu} + 
\tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}) + \tau_{\mu} \mu_{\mu}^2 +
\tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}  \boldsymbol{y} \\


&amp;=&amp; \tau_{\mu} \mu_{\mu}^2 + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}  \boldsymbol{y}   +
(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})
\left(\mu - \frac{\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}}{\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1}}\right)^2 \\

&amp;+&amp; \frac{(\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1})^2}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})}\\

\end{eqnarray*}\]</span></p>
<p>that can be be plugged back into our equation as a
<span class="math inline">\(\text{Normal}(\frac{\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})}, (\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})^{-1})\)</span>:</p>
<p><span class="math display">\[\begin{eqnarray*}
\pi(\boldsymbol{y} | k, \tau_\mu, \mu_\mu, \alpha, \beta)

&amp;=&amp; \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times \tau_\mu^{1/2} 
 \tau^{N/2} |\Psi|^{-1/2}\partial\tau  \\
&amp;\times&amp; \int \exp \left[ -\frac{1}{2} [\tau_\mu (\mu - \mu_\mu)^2 + \tau (\boldsymbol{y} - \mu \boldsymbol{M1})^T \boldsymbol{\Psi}^{-1} (\boldsymbol{y} - \mu \boldsymbol{M1})] \right]  \partial\mu \\ 


&amp;=&amp; \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times \tau_\mu^{1/2} \tau^{N/2} |\Psi|^{-1/2}\partial\tau  
 \exp \left[ -\frac{1}{2}\{ \tau_{\mu} \mu_{\mu}^2 + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y}\} \right]  \\ 
 
&amp;\times&amp; \exp \left[ -\frac{1}{2} \left \{ 
 \frac{(\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1})^2}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1})} \right \} \right]\\
 
&amp;\times&amp; \int \exp \left[ -\frac{1}{2} [
(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1})
\left(\mu - \frac{\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}}{\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}}\right)^2 
\right] \\ 

&amp;\times&amp; \frac{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})^{1/2}}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1})^{1/2}} \thinspace
\thinspace \thinspace \partial\mu \\ 

&amp;=&amp; \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times \tau_\mu^{1/2} 
 \tau^{N/2} |\Psi|^{-1/2} 
 \exp \left[ -\frac{1}{2}\{ \tau_{\mu} \mu_{\mu}^2 + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y}\} \right] \\ 
&amp;\times&amp; \exp \left[ -\frac{1}{2} \left \{ 
 \frac{(\tau_{\mu} \mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi} ^{-1} \boldsymbol{M1})^2}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})} \right \} \right] \frac{1}{(\tau_{\mu} + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1})^{1/2}} \thinspace
\thinspace \thinspace \partial\tau \\ 

\end{eqnarray*}\]</span></p>
<p><strong>Now, replacing <span class="math inline">\(\tau_{\mu} = k \tau\)</span>, we have:</strong></p>
<p><span class="math display">\[\begin{eqnarray*}
\pi(\boldsymbol{y} | k, \mu_\mu, \alpha, \beta, \tau)

&amp;=&amp; \int \tau^{\alpha - 1} \exp [ -\beta \tau] \times (k \tau)^{1/2} 
 \tau^{N/2} |\Psi|^{-1/2} 
 \exp \left[ -\frac{1}{2}\{ k \tau\mu_{\mu}^2 + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y}\} \right] \\
 
&amp;\times&amp; \exp \left[ -\frac{1}{2} \left \{ 
 \frac{(k \tau\mu_{\mu} + \tau \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{1})^2}{(k \tau + \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})} \right \} \right] \frac{1}{(k \tau+ \tau \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1})^{1/2}} \thinspace
\thinspace \thinspace \partial\tau \\ 


&amp;=&amp; |\Psi|^{-1/2}  k^{1/2} \int \tau^{\alpha - 1} \tau^{1/2} \tau^{N/2}
\exp [ -\beta \tau] \times

\exp \left[ -\frac{\tau}{2}\{ k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y}\} \right] \\ 
&amp;\times&amp; \exp \left[ -\frac{1}{2} \left \{ 
 \frac{(\tau (k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{M1}))^2}{ (\tau (k + \boldsymbol{1}^{T}\boldsymbol{\Psi}\boldsymbol{1})} \right \} \right] \frac{1}{(\tau (k +   \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1} \boldsymbol{1}))^{1/2}} \thinspace
\thinspace \thinspace \partial\tau \\ 

&amp;=&amp; |\Psi|^{-1/2}  k^{1/2} \frac{1}{(k + \boldsymbol{1}^{T} \boldsymbol{\Psi}^{-1} \boldsymbol{1})^{1/2}}
\int \tau^{\alpha - 1} \tau^{N/2} \\

&amp;\times&amp; \exp [ -\beta \tau] \times 
\exp \left[ -\frac{\tau}{2}\{ k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} +
\boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}} \} \right] 
\thinspace \thinspace \partial\tau \\ 

&amp;=&amp; |\Psi|^{-1/2}  k^{1/2} \frac{1}{(k + \boldsymbol{1}^{T} \boldsymbol{\Psi}^{-1} \boldsymbol{1})^{1/2}}
\int \tau^{N/2 + \alpha - 1} \\

&amp;\times&amp; \exp [ -\tau \{ \beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}} ) \}]
\thinspace \thinspace \partial\tau \\ 

\end{eqnarray*}\]</span></p>
<p>where the main expression can be seen as a
<span class="math inline">\(\text{Gamma}(N/2 + \alpha, \beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}} ))\)</span></p>
<p>and:</p>
<p><span class="math display">\[\begin{eqnarray*}
\pi(\boldsymbol{y} | k, \mu_\mu, \alpha, \beta)

&amp;=&amp; |\Psi|^{-1/2}  k^{1/2} \frac{1}{(k + \boldsymbol{1}^{T} \boldsymbol{\Psi}^{-1}\boldsymbol{1})^{1/2}}
\int \tau^{N/2 + \alpha - 1} \\
&amp;\times&amp; \exp [ -\tau \{ \beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}} ) \}]
\thinspace \thinspace \\

&amp;\times&amp; \frac{
(\beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}}))^{N/2 + \alpha}
}{
(\beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}}))^{N/2 + \alpha}
} \partial\tau \\ 

&amp;=&amp; |\Psi|^{-1/2}  k^{1/2} \frac{1}{k + (\boldsymbol{1}^{T} \boldsymbol{\Psi}^{-1}\boldsymbol{1})^{1/2}} \\
&amp;\times&amp;
(\beta + \frac{1}{2}(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} +
\boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}}))^{-(N/2 + \alpha)}\\ 

\end{eqnarray*}\]</span></p>
<p>This equation in log-scale gives us:</p>
<p><span class="math display">\[\begin{eqnarray*}
\log(\pi(\boldsymbol{y} | k, \mu_\mu, \alpha, \beta)) &amp;=&amp; 
-\frac{1}{2} \log(|\boldsymbol{\Psi}|) + 
\frac{\log(k)}{2} - \log(k + ((\boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1})^{1/2})) \\
&amp;-&amp; (N/2 + \alpha)\left[ \log \beta + \log(1/2) + \log(k \mu_{\mu}^2 + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1} \boldsymbol{y} + \frac{(k \mu_{\mu} + \boldsymbol{y}^T \boldsymbol{\Psi}^{-1}\boldsymbol{M1})^2}{k + \boldsymbol{1}^{T}\boldsymbol{\Psi}^{-1}\boldsymbol{1}}) \right]

\end{eqnarray*}\]</span></p>
<p>And the same, when written for <span class="math inline">\(j = 1,\dots, b\)</span> nodes
of a tree, would look like:</p>
<p><span class="math display">\[\begin{eqnarray*}
\sum_{j = 1}^{b} \log(\pi(\boldsymbol{y_{j}} | k_{j}, \mu_{\mu_{j}}, \alpha, \beta)) &amp;=&amp; 
\sum_{j = 1}^{b} -\frac{1}{2} \log(|\boldsymbol{\Psi_{j}}|) + 
\frac{\log(k_{j})}{2} - \log(k_{j} + ((\boldsymbol{1}^{T}\boldsymbol{\Psi_{j}}^{-1}\boldsymbol{1})^{1/2})) \\
&amp;-&amp; (N_{j}/2 + \alpha) [ \log \beta + \log(1/2) + \log(k_{j} \mu_{\mu_{j}}^2 + \boldsymbol{y_{j}}^T \boldsymbol{\Psi_{j}}^{-1} \boldsymbol{y_{j}} \\ &amp;+&amp; \frac{(k_{j} \mu_{\mu_{j}} 
 \boldsymbol{y_{j}}^T \boldsymbol{\Psi_{j}}^{-1}\boldsymbol{M_{j} 1})^2}{k_{j} + \boldsymbol{1}^{T}\boldsymbol{\Psi_{j}}^{-1}\boldsymbol{1}})]

\end{eqnarray*}\]</span></p>

</div>
</div>
<div id="algorithm" class="section level2" number="2.9">
<h2><span class="header-section-number">2.9</span> Algorithm</h2>
<hr />
<p><strong>Algorithm type</strong>: Metropolis within GIBBS for a hierachical Bayesian (single) tree</p>
<p><strong>Reason</strong>: We have closed posteriors for most parameters, but not for the tree structure</p>
<p><strong>Data</strong>: Target variable <span class="math inline">\(y\)</span>, groups <span class="math inline">\(j = 1,\dots,m\)</span>, set of
features X</p>
<p><strong>Result</strong>: Posterior distributions for all parameters</p>
<hr />
<p><strong>Initialisation</strong>;</p>
<p>Hyper-parameters values for <span class="math inline">\(\alpha, \beta, k_1, k_2\)</span>;</p>
<p>Number of groups <span class="math inline">\(m\)</span>;</p>
<p>Number of observations <span class="math inline">\(N =\sum_{j = 1}^{m} n_j\)</span>;</p>
<p>Number of iterations I;</p>
<ul>
<li><p>define <span class="math inline">\(\mu_{\mu} = 0\)</span>, <span class="math inline">\(\mu^{0}\)</span>, <span class="math inline">\(\tau^{0}\)</span>, and <span class="math inline">\(\mu_j^{0}, j = 1,\dots, m\)</span>
as the initial parameter values</p></li>
<li><p><strong>for</strong> i from 1 to I <strong>do</strong>:</p>
<ul>
<li><p>grow a new <span class="math inline">\(T^{\text{new}}\)</span> tree by either growing, pruning, changing
or swapping a root node</p></li>
<li><p>set <span class="math inline">\(l_{\text{new}}\)</span> = log full conditional for the
new (candidate) tree</p></li>
</ul></li>
</ul>
<center>
<span class="math inline">\(l_{\text{new}} = \sum_{l = 1}^{b_{\text{new}}} -\frac{1}{2} \log(|\boldsymbol{W}_{1,l}|) + \log(\Gamma(N_l/2 + \alpha))\)</span>
<span class="math inline">\(-(N_l/2 + \alpha)\left[ \log \beta + \log\Big(\frac{(\mathbf{y}_l - \mathbf{W}_{0,l})^T \mathbf{W}_{1,l}^{-1} (\mathbf{y}_l - \mathbf{W}_{0,l})}{2} \Big) \right]\)</span>
</center>
<ul>
<li>set <span class="math inline">\(l_{\text{old}}\)</span> = log full conditional for the
previous tree</li>
</ul>
<center>
<span class="math inline">\(l_{\text{old}} = \sum_{l = 1}^{b_{\text{old}}} -\frac{1}{2} \log(|\boldsymbol{W}_{1,l}|) + \log(\Gamma(N_l/2 + \alpha))\)</span>
<span class="math inline">\(-(N_l/2 + \alpha)\left[ \log \beta + \log\Big(\frac{(\mathbf{y}_l - \mathbf{W}_{0,l})^T \mathbf{W}_{1,l}^{-1} (\mathbf{y}_l - \mathbf{W}_{0,l})}{2} \Big) \right]\)</span>
</center>
<ul>
<li><p>set <span class="math inline">\(a = \exp(l_{\text{new}} - l_{\text{old}})\)</span></p></li>
<li><p>generate <span class="math inline">\(u \sim U[0, 1]\)</span></p></li>
<li><p><strong>if</strong> <span class="math inline">\(u &lt; a\)</span> <strong>then</strong>:</p>
<ul>
<li>set <span class="math inline">\(T = T^{\text{new}}\)</span></li>
</ul></li>
<li><p><strong>end</strong></p></li>
<li><p>sample <span class="math inline">\(\mu\)</span> from the posterior <span class="math inline">\(N(\frac{(\tau/k_1) \bar \mu m}{\tau(\frac{1}{k_2} + \frac{m}{k_1})}, (\tau(\frac{1}{k_2} + \frac{m}{k_1}) )^{-1})\)</span> (because of <span class="math inline">\(\bar \mu\)</span>)</p></li>
<li><p><strong>for</strong> j in 1:m <strong>do</strong>:</p>
<ul>
<li>sample <span class="math inline">\(\mu_j\)</span> from the posterior <span class="math inline">\(N(\frac{\mu/k_1 + \bar y_j n_j}{n_j + 1/k_1}, ((n_j + \frac{1}{k_1})\tau)^{-1})\)</span></li>
</ul></li>
<li><p><strong>end</strong></p></li>
<li><p>sample <span class="math inline">\(\tau\)</span> from the posterior <span class="math inline">\(\text{Gamma}\Big(n/2 + \alpha, \beta + \frac{(\mathbf{y} - \mathbf{W}_0)^T \mathbf{W}_1^{-1} (\mathbf{y} - \mathbf{W}_0)}{2}\Big)\)</span></p></li>
<li><p><strong>end</strong></p></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="finding-a-new-conditional-for-mu-j.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book2.pdf", "book2.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
